{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3y-11-e-Lf4p",
    "outputId": "725abcc8-aa3a-4d8d-9328-0b009b55852a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to initialize NVML: Unknown Error\n"
     ]
    }
   ],
   "source": [
    "#check which GPU we got\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31OW0dhozvli"
   },
   "source": [
    "## 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PVF3W2CmAWPl",
    "outputId": "65e7975e-92bc-472e-a219-7294e3f98783"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting transformers==2.8.0\n",
      "  Downloading transformers-2.8.0-py3-none-any.whl (563 kB)\n",
      "\u001b[K     |████████████████████████████████| 563 kB 5.3 MB/s \n",
      "\u001b[?25hCollecting tokenizers==0.5.2\n",
      "  Downloading tokenizers-0.5.2-cp37-cp37m-manylinux1_x86_64.whl (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 35.5 MB/s \n",
      "\u001b[?25hCollecting boto3\n",
      "  Downloading boto3-1.24.5-py3-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 46.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (4.64.0)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 57.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2.23.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (1.21.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2019.12.20)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "\u001b[K     |████████████████████████████████| 880 kB 62.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (3.7.0)\n",
      "Collecting botocore<1.28.0,>=1.27.5\n",
      "  Downloading botocore-1.27.5-py3-none-any.whl (8.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.9 MB 49.8 MB/s \n",
      "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
      "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
      "\u001b[K     |████████████████████████████████| 79 kB 9.9 MB/s \n",
      "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
      "Collecting urllib3<1.27,>=1.25.4\n",
      "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
      "\u001b[K     |████████████████████████████████| 138 kB 77.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.5->boto3->transformers==2.8.0) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.5->boto3->transformers==2.8.0) (1.15.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2.10)\n",
      "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 51.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2022.5.18.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (1.1.0)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=40dec0310ad701033d4d2a39ac2b20643fe9966f53bae101a3e207e515298abf\n",
      "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: urllib3, jmespath, botocore, s3transfer, tokenizers, sentencepiece, sacremoses, boto3, transformers\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.24.3\n",
      "    Uninstalling urllib3-1.24.3:\n",
      "      Successfully uninstalled urllib3-1.24.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "Successfully installed boto3-1.24.5 botocore-1.27.5 jmespath-1.0.0 s3transfer-0.6.0 sacremoses-0.0.53 sentencepiece-0.1.96 tokenizers-0.5.2 transformers-2.8.0 urllib3-1.25.11\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==2.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_lTXsMK3sNYr",
    "outputId": "e588d121-0044-451d-e6d5-9e2694f60fe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizer\n",
    "import pickle\n",
    "\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u07WRKnxsX96"
   },
   "source": [
    "## 2. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9l_V_SOMFer2",
    "outputId": "d4f31d5f-7768-4cea-9bb0-e51af91dd831"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:24000 tweets\n",
      "Val data:8000 tweets\n",
      "Test data:8000 tweets\n",
      "Labels:\n",
      "{'Irrelevant': 0, 'Negative': 1, 'Neutral': 2, 'Positive': 3}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = \"data/cleaned_labelled_text.csv\" #@param {type:\"string\"}\n",
    "data=pd.read_csv(file_path ,encoding='latin-1')\n",
    "\n",
    "# remove nan\n",
    "data=data.dropna()\n",
    "# sample only some of the data to make the training faster\n",
    "n_sample= 40000 #@param{type:\"integer\"}\n",
    "data=data.sample(n= n_sample, random_state=11) \n",
    "\n",
    "#encode the label to integers\n",
    "le = preprocessing.LabelEncoder()\n",
    "data['label']=le.fit_transform(data['sentiment'].values)\n",
    "le_name_mapping = {le.classes_[i]: le.transform(le.classes_)[i] for i in range(len(le.classes_))}\n",
    "\n",
    "\n",
    "tweets = data.tweet.values\n",
    "labels = data.label.values\n",
    "\n",
    "\n",
    "# train-val-test-split\n",
    "train_ratio = 0.6 #@param{type:\"number\"}\n",
    "validation_ratio = 0.2 #@param{type:\"number\"}\n",
    "test_ratio = 0.2 #@param{type:\"number\"}\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(tweets, labels, test_size=1 - train_ratio, random_state=11)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), random_state=11)\n",
    "\n",
    "print(\"Train data:{} tweets\".format(len(y_train)))\n",
    "print(\"Val data:{} tweets\".format(len(y_val)))\n",
    "print(\"Test data:{} tweets\".format(len(y_test)))\n",
    "\n",
    "\n",
    "print(\"Labels:\")\n",
    "print(le_name_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXgBhZ9L9vqS"
   },
   "source": [
    "## 3. Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9j6EbXLs12Kz"
   },
   "source": [
    "### 3.1 Baseline: TF-IDF + SVM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vU754-QPAwBt"
   },
   "source": [
    "#### Preprocessing\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_OzXFcfCBOa"
   },
   "source": [
    "In the bag-of-words model, a text is represented as the bag of its words, disregarding grammar and word order. Therefore, we will want to remove stop words, punctuations and characters that don't contribute much to the sentence's meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "98rwWTSw_dEI"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def text_preprocessing(s):\n",
    "    \"\"\"\n",
    "    - Lowercase the sentence\n",
    "    - Change \"'t\" to \"not\"\n",
    "    - Remove \"@name\"\n",
    "    - Isolate and remove punctuations except \"?\"\n",
    "    - Remove other special characters\n",
    "    - Remove stop words except \"not\" and \"can\"\n",
    "    - Remove trailing whitespace\n",
    "    \"\"\"\n",
    "    s = s.lower()\n",
    "    # Change 't to 'not'\n",
    "    s = re.sub(r\"\\'t\", \" not\", s)\n",
    "    # Remove @name\n",
    "    s = re.sub(r'(@.*?)[\\s]', ' ', s)\n",
    "    # Isolate and remove punctuations except '?'\n",
    "    s = re.sub(r'([\\'\\\"\\.\\(\\)\\!\\?\\\\\\/\\,])', r' \\1 ', s)\n",
    "    s = re.sub(r'[^\\w\\s\\?]', ' ', s)\n",
    "    # Remove some special characters\n",
    "    s = re.sub(r'([\\;\\:\\|•«\\n])', ' ', s)\n",
    "    # Remove stopwords except 'not' and 'can'\n",
    "    s = \" \".join([word for word in s.split()\n",
    "                  if word not in stopwords.words('english')\n",
    "                  or word in ['not', 'can']])\n",
    "    # Remove trailing whitespace\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    \n",
    "    return s\n",
    "\n",
    "\n",
    "# Preprocess text\n",
    "x_train_preprocessed = np.array([text_preprocessing(text) for text in x_train])\n",
    "x_val_preprocessed = np.array([text_preprocessing(text) for text in x_val])\n",
    "x_test_preprocessed = np.array([text_preprocessing(text) for text in x_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5ypFT51ZvbF"
   },
   "source": [
    "#### **Skip training if you just want to evaluate**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p85t6tfA-9RT"
   },
   "source": [
    "#### Training\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mN5Tm9SL_EO9"
   },
   "source": [
    "##### TF-IDF + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ZT9ShroRhAG"
   },
   "outputs": [],
   "source": [
    "\n",
    "# initiate model\n",
    "cv=CountVectorizer(ngram_range=(1, 3), binary=True)\n",
    "tfidf= TfidfTransformer(smooth_idf=False)\n",
    "svc=SVC(C=1.0, kernel='linear', degree=3, gamma='auto',probability=True)\n",
    "\n",
    "\n",
    "components = [(\"vect\", cv), \n",
    "        (\"tfidf\", tfidf),\n",
    "        (\"svm\", svc)]\n",
    "pipe = Pipeline(components)\n",
    "pipe.fit(x_train_preprocessed,y_train )\n",
    "# save model\n",
    "filename = 'SVM.pkl'\n",
    "model_dir = '/content/drive/MyDrive/Celonis/trained_models/' #@param{type:\"string\"}\n",
    "pickle.dump(pipe, open(model_dir+filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0mtCC3_BEZo"
   },
   "source": [
    "#### Evaluation on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tD58gBmAPwT-",
    "outputId": "7aa7716a-ad5a-4a43-a30d-3f64ae2f5c6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.89      0.73      0.80      1377\n",
      "    Negative       0.83      0.92      0.87      2497\n",
      "     Neutral       0.87      0.80      0.83      1956\n",
      "    Positive       0.82      0.87      0.84      2170\n",
      "\n",
      "    accuracy                           0.84      8000\n",
      "   macro avg       0.85      0.83      0.84      8000\n",
      "weighted avg       0.85      0.84      0.84      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#load model\n",
    "model_path = '/content/drive/MyDrive/Celonis/trained_models/SVM.pkl' #@param{type:\"string\"}\n",
    "with open(model_path , 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "# predic test dataset\n",
    "y_pred= model.predict(x_test_preprocessed)\n",
    "print(classification_report(y_test, y_pred,target_names=list(le_name_mapping.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSiK5sjEV8xH"
   },
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qtmNFujnPytb"
   },
   "outputs": [],
   "source": [
    "def svm_predict_text(model, text):\n",
    "    config={\n",
    "      \"CLASS_NAMES\": [\n",
    "        'Irrelevant', \n",
    "        'Negative', \n",
    "        'Neutral', \n",
    "        'Positive'\n",
    "      ]\n",
    "    }\n",
    "    preprocessed_text = text_preprocessing(text)\n",
    "    probabilities = model.predict_proba([preprocessed_text])\n",
    "    probabilities = torch.from_numpy(probabilities)\n",
    "    confidence, predicted_class = torch.max(probabilities, dim=1)\n",
    "    predicted_class = predicted_class.cpu().item()\n",
    "    probabilities = probabilities.flatten().cpu().numpy().tolist()\n",
    "    return (\n",
    "            config[\"CLASS_NAMES\"][predicted_class],\n",
    "            confidence.cpu().numpy(),\n",
    "            dict(zip(config[\"CLASS_NAMES\"], probabilities)),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p6udwVPGWLFc"
   },
   "outputs": [],
   "source": [
    "#load model\n",
    "model_path = '/content/drive/MyDrive/Celonis/trained_models/SVM.pkl' #@param{type:\"string\"}\n",
    "with open(model_path , 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NsmCWgroZbCX",
    "outputId": "e59f44ea-aa6d-4f63-8b84-3d3e50259d1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Positive',\n",
       " array([0.96006976]),\n",
       " {'Irrelevant': 0.0046383965079831195,\n",
       "  'Negative': 0.03509365974418417,\n",
       "  'Neutral': 0.0001981832508759987,\n",
       "  'Positive': 0.9600697604969568})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict \n",
    "text = \"just played gta i think i should play other games\"#@param{type:\"string\"}\n",
    "svm_predict_text(model,text )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEPPYHa62JXF"
   },
   "source": [
    "### 3.2 BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1SHK30JC1Rw"
   },
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K7hxtI4l0SUJ",
    "outputId": "04765b39-6e21-456b-ce74-4f8af954125a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4sXctSh4sq0"
   },
   "source": [
    "#### Preprocessing and Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNE9oASMZ1bN"
   },
   "source": [
    "Before tokenizing, we need to  check the distribution of the length of our sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384,
     "referenced_widgets": [
      "1efbc257acf34799a229416bf3949ac6",
      "48760076390940659b2410f899d25c29",
      "b4e1abe735774de99a74990c1c35fd5b",
      "12bb98f0094f46728cbe28aee16ddd8b",
      "f612e71b983f4ebb8d6a2a05815cb034",
      "d5fe82b81731427bbb5811879165a3e2",
      "175ffd8bc76f4c97838e4d55810442de",
      "b0b2959cac6c497c96e3af39ba30a01f",
      "78e349dbec594a5292b7f1e696324e9b",
      "6efff40418ae420f8e6ea844f578b545",
      "ad9648c5f7f14ba9a1a0b88e89e71ac1"
     ]
    },
    "id": "hrbvKGNAlMtt",
    "outputId": "7ea3b395-ad5c-42f8-d6ce-192c7ce5a8c7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1efbc257acf34799a229416bf3949ac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([2.4831e+04, 1.1828e+04, 3.1360e+03, 1.1300e+02, 1.9000e+01,\n",
       "        3.9000e+01, 2.6000e+01, 5.0000e+00, 2.0000e+00, 1.0000e+00]),\n",
       " array([  2. ,  33.3,  64.6,  95.9, 127.2, 158.5, 189.8, 221.1, 252.4,\n",
       "        283.7, 315. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "# Encode the tweets\n",
    "encoded_tweets = [tokenizer.encode(sent, add_special_tokens=True) for sent in tweets]\n",
    "\n",
    "# Find length distribution\n",
    "lengths=[len(sent) for sent in encoded_tweets]\n",
    "plt.hist(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QTlQzTzAfCy7"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Specify `MAX_LEN`\n",
    "MAX_LEN = 64 #@param {type:\"integer\"}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygbZpK6qbIYE"
   },
   "source": [
    "The level of processing here is much less than in previous approachs because BERT was trained with the entire sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4L_Rc7l4bgzJ"
   },
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    \"\"\"\n",
    "    - Remove entity mentions (eg. '@united')\n",
    "    - Correct errors (eg. '&amp;' to '&')\n",
    "    @param    text (str): a string to be processed.\n",
    "    @return   text (Str): the processed string.\n",
    "    \"\"\"\n",
    "    # Remove '@name'\n",
    "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
    "\n",
    "    # Replace '&amp;' with '&'\n",
    "    text = re.sub(r'&amp;', '&', text)\n",
    "\n",
    "    # Remove trailing whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "# Create a function to tokenize a set of texts\n",
    "def preprocessing_for_bert(data):\n",
    "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
    "    @param    data (np.array): Array of texts to be processed.\n",
    "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
    "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
    "                  tokens should be attended to by the model.\n",
    "    \"\"\"\n",
    "    # Create empty lists to store outputs\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # For every sentence...\n",
    "    for sent in data:\n",
    "        # `encode_plus` will:\n",
    "        #    (1) Tokenize the sentence\n",
    "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
    "        #    (3) Truncate/Pad sentence to max length\n",
    "        #    (4) Map tokens to their IDs\n",
    "        #    (5) Create attention mask\n",
    "        #    (6) Return a dictionary of outputs\n",
    "        encoded_sent = tokenizer.encode_plus(\n",
    "            text=text_preprocessing(sent),  # Preprocess sentence\n",
    "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
    "            max_length=MAX_LEN,                  # Max length to truncate/pad\n",
    "            pad_to_max_length=True,         # Pad sentence to max length\n",
    "            #return_tensors='pt',           # Return PyTorch tensor\n",
    "            return_attention_mask=True      # Return attention mask\n",
    "            )\n",
    "        \n",
    "        # Add the outputs to the lists\n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZU8t5VNfvhY"
   },
   "source": [
    "#### Create Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xHuYEc61gcGL"
   },
   "outputs": [],
   "source": [
    "\n",
    "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
    "batch_size = 32\n",
    "\n",
    "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
    "train_inputs, train_masks = preprocessing_for_bert(x_train)\n",
    "val_inputs, val_masks = preprocessing_for_bert(x_val)\n",
    "test_inputs, test_masks = preprocessing_for_bert(x_test)\n",
    "\n",
    "# Convert other data types to torch.Tensor\n",
    "train_labels = torch.tensor(y_train)\n",
    "val_labels = torch.tensor(y_val)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "\n",
    "# Create the DataLoader for training set\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for validation set\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for test set\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3X3TPdMOYXUU"
   },
   "source": [
    "#### **Skip training if you just want to evaluate**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSRAga-yj17q"
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wCt1I70GXr9"
   },
   "source": [
    "##### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YK41aBFSj5jK"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create the BertClassfier class\n",
    "class BertClassifier(nn.Module):\n",
    "    \"\"\"Bert Model for Classification Tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self, freeze_bert=False):\n",
    "        \"\"\"\n",
    "        @param    bert: a BertModel object\n",
    "        @param    classifier: a torch.nn.Module classifier\n",
    "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
    "        \"\"\"\n",
    "        super(BertClassifier, self).__init__()\n",
    "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
    "        D_in, H, D_out = 768, 50, 4\n",
    "\n",
    "        # Instantiate BERT model\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        # Instantiate an one-layer feed-forward classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(D_in, H),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(H, D_out)\n",
    "        )\n",
    "\n",
    "        # Freeze the BERT model\n",
    "        if freeze_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        Feed input to BERT and the classifier to compute logits.\n",
    "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
    "                      max_length)\n",
    "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
    "                      information with shape (batch_size, max_length)\n",
    "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
    "                      num_labels)\n",
    "        \"\"\"\n",
    "        # Feed input to BERT\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask)\n",
    "        \n",
    "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
    "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
    "\n",
    "        # Feed input to classifier to compute logits\n",
    "        logits = self.classifier(last_hidden_state_cls)\n",
    "\n",
    "        return logits\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwNrCgPh-yR7"
   },
   "source": [
    "##### Optimizer & Learning Rate Schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6iOXiN8-8gc"
   },
   "source": [
    "\n",
    "\n",
    "- Batch size: 16 or 32\n",
    "- Learning rate (Adam): 5e-5, 3e-5 or 2e-5\n",
    "- Number of epochs: 2, 3, 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JX7su7Q_269U"
   },
   "outputs": [],
   "source": [
    "\n",
    "def initialize_model(epochs=4):\n",
    "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
    "    \"\"\"\n",
    "    # Instantiate Bert Classifier\n",
    "    bert_classifier = BertClassifier(freeze_bert=False)\n",
    "\n",
    "    # Tell PyTorch to run the model on GPU\n",
    "    bert_classifier.to(device)\n",
    "\n",
    "    # Create the optimizer\n",
    "    optimizer = AdamW(bert_classifier.parameters(),\n",
    "                      lr=5e-5,    # Default learning rate\n",
    "                      eps=1e-8    # Default epsilon value\n",
    "                      )\n",
    "\n",
    "    # Total number of training steps\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    # Set up the learning rate scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=0, # Default value\n",
    "                                                num_training_steps=total_steps)\n",
    "    return bert_classifier, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41DRNjv4B0Ow"
   },
   "source": [
    "##### Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYU-GQRZG0y8"
   },
   "source": [
    "In each epoch, we will train our model and evaluate its performance on the validation set.\n",
    "\n",
    "Training:\n",
    "- Unpack our data from the dataloader and load the data onto the GPU\n",
    "- Zero out gradients calculated in the previous pass\n",
    "- Perform a forward pass to compute logits and loss\n",
    "- Perform a backward pass to compute gradients (`loss.backward()`)\n",
    "- Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
    "- Update the model's parameters (`optimizer.step()`)\n",
    "- Update the learning rate (`scheduler.step()`)\n",
    "\n",
    "Evaluation:\n",
    "- Unpack our data and load onto the GPU\n",
    "- Forward pass\n",
    "- Compute loss and accuracy rate over the validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xy4HkhyECibW"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Specify loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def set_seed(seed_value=11):\n",
    "    \"\"\"Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
    "    \"\"\"Train the BertClassifier model.\n",
    "    \"\"\"\n",
    "    # Start training loop\n",
    "    print(\"Start training...\\n\")\n",
    "    for epoch_i in range(epochs):\n",
    "        # =======================================\n",
    "        #               Training\n",
    "        # =======================================\n",
    "        # Print the header of the result table\n",
    "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
    "        print(\"-\"*70)\n",
    "\n",
    "        # Measure the elapsed time of each epoch\n",
    "        t0_epoch, t0_batch = time.time(), time.time()\n",
    "\n",
    "        # Reset tracking variables at the beginning of each epoch\n",
    "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
    "\n",
    "        # Put the model into the training mode\n",
    "        model.train()\n",
    "\n",
    "        # For each batch of training data...\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            batch_counts +=1\n",
    "            # Load batch to GPU\n",
    "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            # Zero out any previously calculated gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Perform a forward pass. This will return logits.\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "            # Compute loss and accumulate the loss values\n",
    "            loss = loss_fn(logits, b_labels)\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Perform a backward pass to calculate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # Update parameters and the learning rate\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Print the loss values and time elapsed for every 20 batches\n",
    "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
    "                # Calculate time elapsed for 20 batches\n",
    "                time_elapsed = time.time() - t0_batch\n",
    "\n",
    "                # Print training results\n",
    "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
    "\n",
    "                # Reset batch tracking variables\n",
    "                batch_loss, batch_counts = 0, 0\n",
    "                t0_batch = time.time()\n",
    "\n",
    "        # Calculate the average loss over the entire training data\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        print(\"-\"*70)\n",
    "        # =======================================\n",
    "        #               Evaluation\n",
    "        # =======================================\n",
    "        if evaluation == True:\n",
    "            # After the completion of each training epoch, measure the model's performance\n",
    "            # on our validation set.\n",
    "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
    "\n",
    "            # Print performance over the entire training data\n",
    "            time_elapsed = time.time() - t0_epoch\n",
    "            \n",
    "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
    "            print(\"-\"*70)\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    print(\"Training complete!\")\n",
    "\n",
    "\n",
    "def evaluate(model, val_dataloader):\n",
    "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
    "    on our validation set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "\n",
    "    # For each batch in our validation set...\n",
    "    for batch in val_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(logits, b_labels)\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "        # Get the predictions\n",
    "        preds = torch.argmax(logits, dim=1).flatten()\n",
    "\n",
    "        # Calculate the accuracy rate\n",
    "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "        val_accuracy.append(accuracy)\n",
    "\n",
    "    # Compute the average accuracy and loss over the validation set.\n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wfYw7dJ0U0v6",
    "outputId": "d3f0039e-2010-4440-8eed-14019daed7d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |   20    |   1.336112   |     -      |     -     |   7.50   \n",
      "   1    |   40    |   1.233292   |     -      |     -     |   7.19   \n",
      "   1    |   60    |   1.204908   |     -      |     -     |   7.15   \n",
      "   1    |   80    |   1.184886   |     -      |     -     |   7.05   \n",
      "   1    |   100   |   1.124939   |     -      |     -     |   6.95   \n",
      "   1    |   120   |   1.132629   |     -      |     -     |   6.88   \n",
      "   1    |   140   |   1.086867   |     -      |     -     |   6.82   \n",
      "   1    |   160   |   1.081907   |     -      |     -     |   6.82   \n",
      "   1    |   180   |   1.065788   |     -      |     -     |   6.82   \n",
      "   1    |   200   |   1.134216   |     -      |     -     |   6.85   \n",
      "   1    |   220   |   1.051754   |     -      |     -     |   6.89   \n",
      "   1    |   240   |   1.053235   |     -      |     -     |   6.91   \n",
      "   1    |   260   |   1.050930   |     -      |     -     |   6.96   \n",
      "   1    |   280   |   1.090625   |     -      |     -     |   6.97   \n",
      "   1    |   300   |   1.065393   |     -      |     -     |   6.99   \n",
      "   1    |   320   |   1.085372   |     -      |     -     |   6.96   \n",
      "   1    |   340   |   1.007878   |     -      |     -     |   7.00   \n",
      "   1    |   360   |   0.968837   |     -      |     -     |   6.89   \n",
      "   1    |   380   |   1.004937   |     -      |     -     |   6.89   \n",
      "   1    |   400   |   0.995711   |     -      |     -     |   6.89   \n",
      "   1    |   420   |   0.931785   |     -      |     -     |   6.89   \n",
      "   1    |   440   |   1.001274   |     -      |     -     |   6.90   \n",
      "   1    |   460   |   0.993048   |     -      |     -     |   6.89   \n",
      "   1    |   480   |   0.931362   |     -      |     -     |   6.91   \n",
      "   1    |   500   |   0.986665   |     -      |     -     |   6.90   \n",
      "   1    |   520   |   0.935466   |     -      |     -     |   6.90   \n",
      "   1    |   540   |   0.904425   |     -      |     -     |   6.89   \n",
      "   1    |   560   |   0.905668   |     -      |     -     |   6.89   \n",
      "   1    |   580   |   0.950806   |     -      |     -     |   6.89   \n",
      "   1    |   600   |   0.956751   |     -      |     -     |   6.90   \n",
      "   1    |   620   |   0.950806   |     -      |     -     |   6.93   \n",
      "   1    |   640   |   0.937409   |     -      |     -     |   6.93   \n",
      "   1    |   660   |   0.889044   |     -      |     -     |   6.93   \n",
      "   1    |   680   |   0.931018   |     -      |     -     |   6.93   \n",
      "   1    |   700   |   0.895494   |     -      |     -     |   6.92   \n",
      "   1    |   720   |   0.941073   |     -      |     -     |   6.92   \n",
      "   1    |   740   |   0.955369   |     -      |     -     |   6.92   \n",
      "   1    |   749   |   0.833790   |     -      |     -     |   3.11   \n",
      "----------------------------------------------------------------------\n",
      "   1    |    -    |   1.023992   |  0.869982  |   66.16   |  289.83  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   20    |   0.783345   |     -      |     -     |   7.24   \n",
      "   2    |   40    |   0.823802   |     -      |     -     |   6.91   \n",
      "   2    |   60    |   0.827933   |     -      |     -     |   6.93   \n",
      "   2    |   80    |   0.821951   |     -      |     -     |   6.94   \n",
      "   2    |   100   |   0.785245   |     -      |     -     |   6.94   \n",
      "   2    |   120   |   0.805491   |     -      |     -     |   6.93   \n",
      "   2    |   140   |   0.797647   |     -      |     -     |   6.94   \n",
      "   2    |   160   |   0.752121   |     -      |     -     |   6.92   \n",
      "   2    |   180   |   0.796688   |     -      |     -     |   6.92   \n",
      "   2    |   200   |   0.774024   |     -      |     -     |   6.90   \n",
      "   2    |   220   |   0.792288   |     -      |     -     |   6.89   \n",
      "   2    |   240   |   0.773813   |     -      |     -     |   6.89   \n",
      "   2    |   260   |   0.740998   |     -      |     -     |   6.87   \n",
      "   2    |   280   |   0.795173   |     -      |     -     |   6.90   \n",
      "   2    |   300   |   0.778676   |     -      |     -     |   6.90   \n",
      "   2    |   320   |   0.754152   |     -      |     -     |   6.91   \n",
      "   2    |   340   |   0.819928   |     -      |     -     |   6.91   \n",
      "   2    |   360   |   0.815409   |     -      |     -     |   6.92   \n",
      "   2    |   380   |   0.822581   |     -      |     -     |   6.95   \n",
      "   2    |   400   |   0.806558   |     -      |     -     |   6.94   \n",
      "   2    |   420   |   0.806461   |     -      |     -     |   6.94   \n",
      "   2    |   440   |   0.735545   |     -      |     -     |   6.94   \n",
      "   2    |   460   |   0.737111   |     -      |     -     |   6.93   \n",
      "   2    |   480   |   0.810511   |     -      |     -     |   6.90   \n",
      "   2    |   500   |   0.810346   |     -      |     -     |   6.89   \n",
      "   2    |   520   |   0.785221   |     -      |     -     |   6.89   \n",
      "   2    |   540   |   0.775958   |     -      |     -     |   6.89   \n",
      "   2    |   560   |   0.803009   |     -      |     -     |   6.89   \n",
      "   2    |   580   |   0.820094   |     -      |     -     |   6.90   \n",
      "   2    |   600   |   0.723853   |     -      |     -     |   6.92   \n",
      "   2    |   620   |   0.794850   |     -      |     -     |   6.92   \n",
      "   2    |   640   |   0.875258   |     -      |     -     |   6.95   \n",
      "   2    |   660   |   0.833252   |     -      |     -     |   6.94   \n",
      "   2    |   680   |   0.769465   |     -      |     -     |   6.93   \n",
      "   2    |   700   |   0.771168   |     -      |     -     |   6.92   \n",
      "   2    |   720   |   0.757741   |     -      |     -     |   6.89   \n",
      "   2    |   740   |   0.794427   |     -      |     -     |   6.88   \n",
      "   2    |   749   |   0.774222   |     -      |     -     |   3.09   \n",
      "----------------------------------------------------------------------\n",
      "   2    |    -    |   0.790924   |  0.869982  |   66.16   |  289.31  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   3    |   20    |   0.767526   |     -      |     -     |   7.26   \n",
      "   3    |   40    |   0.785612   |     -      |     -     |   6.93   \n",
      "   3    |   60    |   0.796518   |     -      |     -     |   6.91   \n",
      "   3    |   80    |   0.842624   |     -      |     -     |   6.91   \n",
      "   3    |   100   |   0.807061   |     -      |     -     |   6.90   \n",
      "   3    |   120   |   0.759081   |     -      |     -     |   6.89   \n",
      "   3    |   140   |   0.832151   |     -      |     -     |   6.89   \n",
      "   3    |   160   |   0.772527   |     -      |     -     |   6.90   \n",
      "   3    |   180   |   0.793524   |     -      |     -     |   6.90   \n",
      "   3    |   200   |   0.779949   |     -      |     -     |   6.91   \n",
      "   3    |   220   |   0.799884   |     -      |     -     |   6.90   \n",
      "   3    |   240   |   0.758339   |     -      |     -     |   6.90   \n",
      "   3    |   260   |   0.801502   |     -      |     -     |   6.89   \n",
      "   3    |   280   |   0.785351   |     -      |     -     |   6.90   \n",
      "   3    |   300   |   0.811538   |     -      |     -     |   6.91   \n",
      "   3    |   320   |   0.812765   |     -      |     -     |   6.91   \n",
      "   3    |   340   |   0.719908   |     -      |     -     |   6.93   \n",
      "   3    |   360   |   0.778640   |     -      |     -     |   6.93   \n",
      "   3    |   380   |   0.805136   |     -      |     -     |   6.93   \n",
      "   3    |   400   |   0.800358   |     -      |     -     |   6.92   \n",
      "   3    |   420   |   0.769391   |     -      |     -     |   6.91   \n",
      "   3    |   440   |   0.787678   |     -      |     -     |   6.91   \n",
      "   3    |   460   |   0.802376   |     -      |     -     |   6.89   \n",
      "   3    |   480   |   0.776013   |     -      |     -     |   6.90   \n",
      "   3    |   500   |   0.799228   |     -      |     -     |   6.89   \n",
      "   3    |   520   |   0.812676   |     -      |     -     |   6.90   \n",
      "   3    |   540   |   0.787452   |     -      |     -     |   6.89   \n",
      "   3    |   560   |   0.773999   |     -      |     -     |   6.90   \n",
      "   3    |   580   |   0.777021   |     -      |     -     |   6.90   \n",
      "   3    |   600   |   0.790147   |     -      |     -     |   6.91   \n",
      "   3    |   620   |   0.810231   |     -      |     -     |   6.91   \n",
      "   3    |   640   |   0.809608   |     -      |     -     |   6.93   \n",
      "   3    |   660   |   0.749764   |     -      |     -     |   6.93   \n",
      "   3    |   680   |   0.810433   |     -      |     -     |   6.92   \n",
      "   3    |   700   |   0.760678   |     -      |     -     |   6.94   \n",
      "   3    |   720   |   0.782486   |     -      |     -     |   6.92   \n",
      "   3    |   740   |   0.811976   |     -      |     -     |   6.93   \n",
      "   3    |   749   |   0.782269   |     -      |     -     |   3.11   \n",
      "----------------------------------------------------------------------\n",
      "   3    |    -    |   0.789641   |  0.869982  |   66.16   |  289.01  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   4    |   20    |   0.822810   |     -      |     -     |   7.23   \n",
      "   4    |   40    |   0.782500   |     -      |     -     |   6.89   \n",
      "   4    |   60    |   0.827727   |     -      |     -     |   6.89   \n",
      "   4    |   80    |   0.847559   |     -      |     -     |   6.89   \n",
      "   4    |   100   |   0.835932   |     -      |     -     |   6.92   \n",
      "   4    |   120   |   0.766827   |     -      |     -     |   6.93   \n",
      "   4    |   140   |   0.778640   |     -      |     -     |   6.94   \n",
      "   4    |   160   |   0.809053   |     -      |     -     |   6.95   \n",
      "   4    |   180   |   0.801236   |     -      |     -     |   6.92   \n",
      "   4    |   200   |   0.804344   |     -      |     -     |   6.90   \n",
      "   4    |   220   |   0.756744   |     -      |     -     |   6.91   \n",
      "   4    |   240   |   0.777465   |     -      |     -     |   6.89   \n",
      "   4    |   260   |   0.781469   |     -      |     -     |   6.89   \n",
      "   4    |   280   |   0.773802   |     -      |     -     |   6.89   \n",
      "   4    |   300   |   0.858573   |     -      |     -     |   6.90   \n",
      "   4    |   320   |   0.841282   |     -      |     -     |   6.89   \n",
      "   4    |   340   |   0.732411   |     -      |     -     |   6.90   \n",
      "   4    |   360   |   0.790992   |     -      |     -     |   6.88   \n",
      "   4    |   380   |   0.795682   |     -      |     -     |   6.89   \n",
      "   4    |   400   |   0.722537   |     -      |     -     |   6.90   \n",
      "   4    |   420   |   0.773421   |     -      |     -     |   6.92   \n",
      "   4    |   440   |   0.812793   |     -      |     -     |   6.91   \n",
      "   4    |   460   |   0.735007   |     -      |     -     |   6.93   \n",
      "   4    |   480   |   0.764647   |     -      |     -     |   6.96   \n",
      "   4    |   500   |   0.820861   |     -      |     -     |   6.95   \n",
      "   4    |   520   |   0.779101   |     -      |     -     |   6.93   \n",
      "   4    |   540   |   0.832920   |     -      |     -     |   6.91   \n",
      "   4    |   560   |   0.774065   |     -      |     -     |   6.90   \n",
      "   4    |   580   |   0.782929   |     -      |     -     |   6.89   \n",
      "   4    |   600   |   0.784299   |     -      |     -     |   6.89   \n",
      "   4    |   620   |   0.808515   |     -      |     -     |   6.87   \n",
      "   4    |   640   |   0.756364   |     -      |     -     |   6.89   \n",
      "   4    |   660   |   0.766074   |     -      |     -     |   6.89   \n",
      "   4    |   680   |   0.781797   |     -      |     -     |   6.91   \n",
      "   4    |   700   |   0.787897   |     -      |     -     |   6.92   \n",
      "   4    |   720   |   0.762136   |     -      |     -     |   6.93   \n",
      "   4    |   740   |   0.822427   |     -      |     -     |   6.95   \n",
      "   4    |   749   |   0.781536   |     -      |     -     |   3.13   \n",
      "----------------------------------------------------------------------\n",
      "   4    |    -    |   0.790551   |  0.869982  |   66.16   |  289.22  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "set_seed(11)    # Set seed for reproducibility\n",
    "bert_classifier, optimizer, scheduler = initialize_model(epochs=1)\n",
    "train(bert_classifier, train_dataloader, val_dataloader, epochs=4, evaluation=True)\n",
    "filename = 'model.bin'\n",
    "model_dir = '/content/drive/MyDrive/Celonis/trained_models/'#@param {type:\"string\"}\n",
    "torch.save(bert_classifier.state_dict(), model_dir+filename )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5ostg9kPlra"
   },
   "source": [
    "#### Evaluation on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Em10Wz3Wsj8q",
    "outputId": "bc60af67-f63c-49b2-b929-caf890837a8b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"/content/drive/MyDrive/Celonis/trained_models/model.bin\" #@param {type:\"string\"}\n",
    "bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
    "bert_classifier.load_state_dict(torch.load(model_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V5_w4erqGzpe"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def bert_predict(model, test_dataloader):\n",
    "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
    "    on the test set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    all_logits = []\n",
    "\n",
    "    # For each batch in our test set...\n",
    "    for batch in test_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "        all_logits.append(logits)\n",
    "    \n",
    "    # Concatenate logits from each batch\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "\n",
    "    # Apply softmax to calculate probabilities\n",
    "    probs = F.softmax(all_logits, dim=1)\n",
    "    predicted_class = torch.argmax(probs, dim=1)\n",
    "\n",
    "    return predicted_class\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ao9VfL-DgZuh",
    "outputId": "cc5f011e-d74d-4032-944f-25ca1a9b0eec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Irrelevant       0.58      0.39      0.47      1377\n",
      "    Negative       0.71      0.79      0.75      2497\n",
      "     Neutral       0.65      0.53      0.58      1956\n",
      "    Positive       0.62      0.77      0.69      2170\n",
      "\n",
      "    accuracy                           0.65      8000\n",
      "   macro avg       0.64      0.62      0.62      8000\n",
      "weighted avg       0.65      0.65      0.64      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=bert_predict(bert_classifier,test_dataloader).cpu().numpy()\n",
    "print(classification_report(y_test, y_pred,target_names=list(le_name_mapping.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_LwoYTqUVBN9"
   },
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JOzKVgy2WXJ8"
   },
   "outputs": [],
   "source": [
    "  \n",
    "def bert_predict_text(model, text):\n",
    "    model.eval()\n",
    "    config={\n",
    "      \"CLASS_NAMES\": [\n",
    "        'Irrelevant', \n",
    "        'Negative', \n",
    "        'Neutral', \n",
    "        'Positive'\n",
    "      ]\n",
    "    }\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "    encoded_text = tokenizer.encode_plus(\n",
    "            text=text_preprocessing(text),  # Preprocess sentence\n",
    "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
    "            max_length=MAX_LEN,                  # Max length to truncate/pad\n",
    "            pad_to_max_length=True,         # Pad sentence to max length\n",
    "            return_tensors='pt',           # Return PyTorch tensor\n",
    "            return_attention_mask=True      # Return attention mask\n",
    "            )\n",
    "    input_ids = encoded_text[\"input_ids\"].to(device)\n",
    "    attention_mask = encoded_text[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        probabilities = F.softmax(model(input_ids, attention_mask), dim=1)\n",
    "    confidence, predicted_class = torch.max(probabilities, dim=1)\n",
    "    predicted_class = predicted_class.cpu().item()\n",
    "    probabilities = probabilities.flatten().cpu().numpy().tolist()\n",
    "    return (\n",
    "            config[\"CLASS_NAMES\"][predicted_class],\n",
    "            confidence.cpu().numpy(),\n",
    "            dict(zip(config[\"CLASS_NAMES\"], probabilities)),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "nAxO34OxWZzb",
    "outputId": "06c2dae1-0487-45c5-aa8c-f04d0bc898ec"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-4608bd71fc47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Celonis/trained_models/model.bin\"\u001b[0m \u001b[0;31m#@param {type:\"string\"}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbert_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbert_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-4e3117f1aece>\u001b[0m in \u001b[0;36minitialize_model\u001b[0;34m(epochs)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Instantiate Bert Classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mbert_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreeze_bert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Tell PyTorch to run the model on GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-2b2c3f2a2daa>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, freeze_bert)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Instantiate BERT model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-uncased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Instantiate an one-layer feed-forward classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    586\u001b[0m                 \u001b[0mmodel_to_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m             \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmodel_to_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(module, prefix)\u001b[0m\n\u001b[1;32m    572\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                         \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m             \u001b[0;31m# Make sure we are able to load base models as well as derived models (with heads)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(module, prefix)\u001b[0m\n\u001b[1;32m    572\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                         \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m             \u001b[0;31m# Make sure we are able to load base models as well as derived models (with heads)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(module, prefix)\u001b[0m\n\u001b[1;32m    572\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                         \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m             \u001b[0;31m# Make sure we are able to load base models as well as derived models (with heads)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(module, prefix)\u001b[0m\n\u001b[1;32m    572\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                         \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m             \u001b[0;31m# Make sure we are able to load base models as well as derived models (with heads)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(module, prefix)\u001b[0m\n\u001b[1;32m    572\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                         \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m             \u001b[0;31m# Make sure we are able to load base models as well as derived models (with heads)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(module, prefix)\u001b[0m\n\u001b[1;32m    568\u001b[0m                 \u001b[0mlocal_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m                 module._load_from_state_dict(\n\u001b[0;32m--> 570\u001b[0;31m                     \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_metadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_msgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m                 )\n\u001b[1;32m    572\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_load_from_state_dict\u001b[0;34m(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1413\u001b[0;31m                         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1414\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1415\u001b[0m                     error_msgs.append('While copying the parameter named \"{}\", '\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_path = \"/content/drive/MyDrive/Celonis/trained_models/model.bin\" #@param {type:\"string\"}\n",
    "bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
    "bert_classifier.load_state_dict(torch.load(model_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WtPWKsmFxUiU",
    "outputId": "b1a77ba0-5d0d-428c-b231-91098892b1f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Positive',\n",
       " array([0.59517074], dtype=float32),\n",
       " {'Irrelevant': 0.17862385511398315,\n",
       "  'Negative': 0.06856974214315414,\n",
       "  'Neutral': 0.1576356738805771,\n",
       "  'Positive': 0.5951707363128662})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = bert_classifier\n",
    "text = \"just played gta i think i should play other games\"#@param {type:\"string\"}\n",
    "bert_predict_text(model,text)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "31OW0dhozvli",
    "u07WRKnxsX96",
    "vU754-QPAwBt",
    "p85t6tfA-9RT",
    "mN5Tm9SL_EO9",
    "v0mtCC3_BEZo",
    "s1SHK30JC1Rw",
    "D4sXctSh4sq0",
    "aZU8t5VNfvhY",
    "SSRAga-yj17q",
    "4wCt1I70GXr9",
    "LwNrCgPh-yR7",
    "41DRNjv4B0Ow",
    "D5ostg9kPlra"
   ],
   "name": "Sentiment-Analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "12bb98f0094f46728cbe28aee16ddd8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6efff40418ae420f8e6ea844f578b545",
      "placeholder": "​",
      "style": "IPY_MODEL_ad9648c5f7f14ba9a1a0b88e89e71ac1",
      "value": " 232k/232k [00:00&lt;00:00, 843kB/s]"
     }
    },
    "175ffd8bc76f4c97838e4d55810442de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1efbc257acf34799a229416bf3949ac6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_48760076390940659b2410f899d25c29",
       "IPY_MODEL_b4e1abe735774de99a74990c1c35fd5b",
       "IPY_MODEL_12bb98f0094f46728cbe28aee16ddd8b"
      ],
      "layout": "IPY_MODEL_f612e71b983f4ebb8d6a2a05815cb034"
     }
    },
    "48760076390940659b2410f899d25c29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5fe82b81731427bbb5811879165a3e2",
      "placeholder": "​",
      "style": "IPY_MODEL_175ffd8bc76f4c97838e4d55810442de",
      "value": "Downloading: 100%"
     }
    },
    "6efff40418ae420f8e6ea844f578b545": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78e349dbec594a5292b7f1e696324e9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ad9648c5f7f14ba9a1a0b88e89e71ac1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b0b2959cac6c497c96e3af39ba30a01f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4e1abe735774de99a74990c1c35fd5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0b2959cac6c497c96e3af39ba30a01f",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_78e349dbec594a5292b7f1e696324e9b",
      "value": 231508
     }
    },
    "d5fe82b81731427bbb5811879165a3e2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f612e71b983f4ebb8d6a2a05815cb034": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
