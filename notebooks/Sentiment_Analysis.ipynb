{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xlRLxRMFN-d",
        "outputId": "cab8c3c3-8791-46e9-ec1c-b84e7891d8c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\danie\\Documents\\My Projects\\sentiment-analysis-challenge\n"
          ]
        }
      ],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3y-11-e-Lf4p",
        "outputId": "725abcc8-aa3a-4d8d-9328-0b009b55852a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Jun  9 11:04:00 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "#check which GPU we got\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31OW0dhozvli"
      },
      "source": [
        "## 1. Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVF3W2CmAWPl",
        "outputId": "65e7975e-92bc-472e-a219-7294e3f98783"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==2.8.0\n",
            "  Downloading transformers-2.8.0-py3-none-any.whl (563 kB)\n",
            "\u001b[K     |████████████████████████████████| 563 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.2\n",
            "  Downloading tokenizers-0.5.2-cp37-cp37m-manylinux1_x86_64.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 35.5 MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.24.5-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 46.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (4.64.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 57.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 62.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (3.7.0)\n",
            "Collecting botocore<1.28.0,>=1.27.5\n",
            "  Downloading botocore-1.27.5-py3-none-any.whl (8.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.9 MB 49.8 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 9.9 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 77.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.5->boto3->transformers==2.8.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.5->boto3->transformers==2.8.0) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2.10)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 51.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=40dec0310ad701033d4d2a39ac2b20643fe9966f53bae101a3e207e515298abf\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, tokenizers, sentencepiece, sacremoses, boto3, transformers\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.24.5 botocore-1.27.5 jmespath-1.0.0 s3transfer-0.6.0 sacremoses-0.0.53 sentencepiece-0.1.96 tokenizers-0.5.2 transformers-2.8.0 urllib3-1.25.11\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==2.8.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lTXsMK3sNYr",
        "outputId": "e588d121-0044-451d-e6d5-9e2694f60fe1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import torch\n",
        "\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertTokenizer\n",
        "import pickle\n",
        "\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "import random\n",
        "import time\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u07WRKnxsX96"
      },
      "source": [
        "## 2. Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9l_V_SOMFer2",
        "outputId": "36903f6f-01b3-4362-b2b4-10470f9fe2c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data:24000 tweets\n",
            "Val data:8000 tweets\n",
            "Test data:8000 tweets\n",
            "Labels:\n",
            "{'Irrelevant': 0, 'Negative': 1, 'Neutral': 2, 'Positive': 3}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "file_path = \"data/cleaned_labelled_text.csv\" #@param {type:\"string\"}\n",
        "data=pd.read_csv(file_path ,encoding='latin-1')\n",
        "\n",
        "# remove nan\n",
        "data=data.dropna()\n",
        "# sample only some of the data to make the training faster\n",
        "n_sample= 40000 #@param{type:\"integer\"}\n",
        "data=data.sample(n= n_sample, random_state=11) \n",
        "\n",
        "#encode the label to integers\n",
        "le = preprocessing.LabelEncoder()\n",
        "data['label']=le.fit_transform(data['sentiment'].values)\n",
        "le_name_mapping = {le.classes_[i]: le.transform(le.classes_)[i] for i in range(len(le.classes_))}\n",
        "\n",
        "\n",
        "tweets = data.tweet.values\n",
        "labels = data.label.values\n",
        "\n",
        "\n",
        "# train-val-test-split\n",
        "train_ratio = 0.6 #@param{type:\"number\"}\n",
        "validation_ratio = 0.2 #@param{type:\"number\"}\n",
        "test_ratio = 0.2 #@param{type:\"number\"}\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(tweets, labels, test_size=1 - train_ratio, random_state=11)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), random_state=11)\n",
        "\n",
        "print(\"Train data:{} tweets\".format(len(y_train)))\n",
        "print(\"Val data:{} tweets\".format(len(y_val)))\n",
        "print(\"Test data:{} tweets\".format(len(y_test)))\n",
        "\n",
        "\n",
        "print(\"Labels:\")\n",
        "print(le_name_mapping)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXgBhZ9L9vqS"
      },
      "source": [
        "## 3. Models "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j6EbXLs12Kz"
      },
      "source": [
        "### 3.1 Baseline: TF-IDF + SVM\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU754-QPAwBt"
      },
      "source": [
        "#### Preprocessing\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_OzXFcfCBOa"
      },
      "source": [
        "In the bag-of-words model, a text is represented as the bag of its words, disregarding grammar and word order. Therefore, we will want to remove stop words, punctuations and characters that don't contribute much to the sentence's meaning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "98rwWTSw_dEI"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def text_preprocessing(s):\n",
        "    \"\"\"\n",
        "    - Lowercase the sentence\n",
        "    - Change \"'t\" to \"not\"\n",
        "    - Remove \"@name\"\n",
        "    - Isolate and remove punctuations except \"?\"\n",
        "    - Remove other special characters\n",
        "    - Remove stop words except \"not\" and \"can\"\n",
        "    - Remove trailing whitespace\n",
        "    \"\"\"\n",
        "    s = s.lower()\n",
        "    # Change 't to 'not'\n",
        "    s = re.sub(r\"\\'t\", \" not\", s)\n",
        "    # Remove @name\n",
        "    s = re.sub(r'(@.*?)[\\s]', ' ', s)\n",
        "    # Isolate and remove punctuations except '?'\n",
        "    s = re.sub(r'([\\'\\\"\\.\\(\\)\\!\\?\\\\\\/\\,])', r' \\1 ', s)\n",
        "    s = re.sub(r'[^\\w\\s\\?]', ' ', s)\n",
        "    # Remove some special characters\n",
        "    s = re.sub(r'([\\;\\:\\|•«\\n])', ' ', s)\n",
        "    # Remove stopwords except 'not' and 'can'\n",
        "    s = \" \".join([word for word in s.split()\n",
        "                  if word not in stopwords.words('english')\n",
        "                  or word in ['not', 'can']])\n",
        "    # Remove trailing whitespace\n",
        "    s = re.sub(r'\\s+', ' ', s).strip()\n",
        "    \n",
        "    return s\n",
        "\n",
        "\n",
        "# Preprocess text\n",
        "x_train_preprocessed = np.array([text_preprocessing(text) for text in x_train])\n",
        "x_test_preprocessed = np.array([text_preprocessing(text) for text in x_test])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p85t6tfA-9RT"
      },
      "source": [
        "#### Training\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mN5Tm9SL_EO9"
      },
      "source": [
        "##### TF-IDF + SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-ZT9ShroRhAG"
      },
      "outputs": [],
      "source": [
        "\n",
        "# initiate model\n",
        "cv=CountVectorizer(ngram_range=(1, 3), binary=True)\n",
        "tfidf= TfidfTransformer(smooth_idf=False)\n",
        "svc=SVC(C=1.0, kernel='linear', degree=3, gamma='auto',probability=True)\n",
        "\n",
        "\n",
        "components = [(\"vect\", cv), \n",
        "        (\"tfidf\", tfidf),\n",
        "        (\"svm\", svc)]\n",
        "pipe = Pipeline(components)\n",
        "pipe.fit(x_train_preprocessed,y_train )\n",
        "# save model\n",
        "filename = 'SVM.pkl'\n",
        "model_dir = '/models/' #@param{type:\"string\"}\n",
        "pickle.dump(pipe, open(model_dir+filename, 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0mtCC3_BEZo"
      },
      "source": [
        "#### Evaluation on Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tD58gBmAPwT-",
        "outputId": "27b866c0-f8d3-456a-90ee-13ad2fdccfd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Irrelevant       0.89      0.73      0.80      1377\n",
            "    Negative       0.83      0.92      0.87      2497\n",
            "     Neutral       0.87      0.80      0.83      1956\n",
            "    Positive       0.82      0.87      0.84      2170\n",
            "\n",
            "    accuracy                           0.84      8000\n",
            "   macro avg       0.85      0.83      0.84      8000\n",
            "weighted avg       0.85      0.84      0.84      8000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#load model\n",
        "model_path = 'models/SVM.pkl' #@param{type:\"string\"}\n",
        "with open(model_path , 'rb') as f:\n",
        "    model = pickle.load(f)\n",
        "# predic test dataset\n",
        "y_pred= model.predict(x_test_preprocessed)\n",
        "print(classification_report(y_test, y_pred,target_names=list(le_name_mapping.keys())))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSiK5sjEV8xH"
      },
      "source": [
        "#### Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "qtmNFujnPytb"
      },
      "outputs": [],
      "source": [
        "def svm_predict_text(model, text):\n",
        "    config={\n",
        "      \"CLASS_NAMES\": [\n",
        "        'Irrelevant', \n",
        "        'Negative', \n",
        "        'Neutral', \n",
        "        'Positive'\n",
        "      ]\n",
        "    }\n",
        "    preprocessed_text = text_preprocessing(text)\n",
        "    probabilities = model.predict_proba([preprocessed_text])\n",
        "    probabilities = torch.from_numpy(probabilities)\n",
        "    confidence, predicted_class = torch.max(probabilities, dim=1)\n",
        "    predicted_class = predicted_class.cpu().item()\n",
        "    probabilities = probabilities.flatten().cpu().numpy().tolist()\n",
        "    return (\n",
        "            config[\"CLASS_NAMES\"][predicted_class],\n",
        "            confidence.cpu().numpy(),\n",
        "            dict(zip(config[\"CLASS_NAMES\"], probabilities)),\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "p6udwVPGWLFc"
      },
      "outputs": [],
      "source": [
        "#load model\n",
        "model_path = 'models/SVM.pkl' #@param{type:\"string\"}\n",
        "with open(model_path , 'rb') as f:\n",
        "    model = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsmCWgroZbCX",
        "outputId": "e59f44ea-aa6d-4f63-8b84-3d3e50259d1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('Positive',\n",
              " array([0.96006976]),\n",
              " {'Irrelevant': 0.0046383965079831195,\n",
              "  'Negative': 0.03509365974418417,\n",
              "  'Neutral': 0.0001981832508759987,\n",
              "  'Positive': 0.9600697604969568})"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# predict \n",
        "text = \"just played gta i think i should play other games\"#@param{type:\"string\"}\n",
        "svm_predict_text(model,text )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEPPYHa62JXF"
      },
      "source": [
        "### 3.2 BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1SHK30JC1Rw"
      },
      "source": [
        "#### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7hxtI4l0SUJ",
        "outputId": "04765b39-6e21-456b-ce74-4f8af954125a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4sXctSh4sq0"
      },
      "source": [
        "#### Preprocessing and Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNE9oASMZ1bN"
      },
      "source": [
        "Before tokenizing, we need to  check the distribution of the length of our sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384,
          "referenced_widgets": [
            "1efbc257acf34799a229416bf3949ac6",
            "48760076390940659b2410f899d25c29",
            "b4e1abe735774de99a74990c1c35fd5b",
            "12bb98f0094f46728cbe28aee16ddd8b",
            "f612e71b983f4ebb8d6a2a05815cb034",
            "d5fe82b81731427bbb5811879165a3e2",
            "175ffd8bc76f4c97838e4d55810442de",
            "b0b2959cac6c497c96e3af39ba30a01f",
            "78e349dbec594a5292b7f1e696324e9b",
            "6efff40418ae420f8e6ea844f578b545",
            "ad9648c5f7f14ba9a1a0b88e89e71ac1"
          ]
        },
        "id": "hrbvKGNAlMtt",
        "outputId": "7ea3b395-ad5c-42f8-d6ce-192c7ce5a8c7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1efbc257acf34799a229416bf3949ac6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "(array([2.4831e+04, 1.1828e+04, 3.1360e+03, 1.1300e+02, 1.9000e+01,\n",
              "        3.9000e+01, 2.6000e+01, 5.0000e+00, 2.0000e+00, 1.0000e+00]),\n",
              " array([  2. ,  33.3,  64.6,  95.9, 127.2, 158.5, 189.8, 221.1, 252.4,\n",
              "        283.7, 315. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "# Encode the tweets\n",
        "encoded_tweets = [tokenizer.encode(sent, add_special_tokens=True) for sent in tweets]\n",
        "\n",
        "# Find length distribution\n",
        "lengths=[len(sent) for sent in encoded_tweets]\n",
        "plt.hist(lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "QTlQzTzAfCy7"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Specify `MAX_LEN`\n",
        "MAX_LEN = 64 #@param {type:\"integer\"}\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygbZpK6qbIYE"
      },
      "source": [
        "The level of processing here is much less than in previous approachs because BERT was trained with the entire sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "4L_Rc7l4bgzJ"
      },
      "outputs": [],
      "source": [
        "def text_preprocessing(text):\n",
        "    \"\"\"\n",
        "    - Remove entity mentions (eg. '@united')\n",
        "    - Correct errors (eg. '&amp;' to '&')\n",
        "    @param    text (str): a string to be processed.\n",
        "    @return   text (Str): the processed string.\n",
        "    \"\"\"\n",
        "    # Remove '@name'\n",
        "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
        "\n",
        "    # Replace '&amp;' with '&'\n",
        "    text = re.sub(r'&amp;', '&', text)\n",
        "\n",
        "    # Remove trailing whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "# Create a function to tokenize a set of texts\n",
        "def preprocessing_for_bert(data):\n",
        "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
        "    @param    data (np.array): Array of texts to be processed.\n",
        "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
        "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
        "                  tokens should be attended to by the model.\n",
        "    \"\"\"\n",
        "    # Create empty lists to store outputs\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in data:\n",
        "        # `encode_plus` will:\n",
        "        #    (1) Tokenize the sentence\n",
        "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
        "        #    (3) Truncate/Pad sentence to max length\n",
        "        #    (4) Map tokens to their IDs\n",
        "        #    (5) Create attention mask\n",
        "        #    (6) Return a dictionary of outputs\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "            text=text_preprocessing(sent),  # Preprocess sentence\n",
        "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
        "            max_length=MAX_LEN,                  # Max length to truncate/pad\n",
        "            pad_to_max_length=True,         # Pad sentence to max length\n",
        "            #return_tensors='pt',           # Return PyTorch tensor\n",
        "            return_attention_mask=True      # Return attention mask\n",
        "            )\n",
        "        \n",
        "        # Add the outputs to the lists\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZU8t5VNfvhY"
      },
      "source": [
        "#### Create Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "xHuYEc61gcGL"
      },
      "outputs": [],
      "source": [
        "\n",
        "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
        "train_inputs, train_masks = preprocessing_for_bert(x_train)\n",
        "val_inputs, val_masks = preprocessing_for_bert(x_val)\n",
        "test_inputs, test_masks = preprocessing_for_bert(x_test)\n",
        "\n",
        "# Convert other data types to torch.Tensor\n",
        "train_labels = torch.tensor(y_train)\n",
        "val_labels = torch.tensor(y_val)\n",
        "test_labels = torch.tensor(y_test)\n",
        "\n",
        "\n",
        "# Create the DataLoader for training set\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for validation set\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for test set\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(val_data, sampler=test_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSRAga-yj17q"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wCt1I70GXr9"
      },
      "source": [
        "##### Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "YK41aBFSj5jK"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Create the BertClassfier class\n",
        "class BertClassifier(nn.Module):\n",
        "    \"\"\"Bert Model for Classification Tasks.\n",
        "    \"\"\"\n",
        "    def __init__(self, freeze_bert=False):\n",
        "        \"\"\"\n",
        "        @param    bert: a BertModel object\n",
        "        @param    classifier: a torch.nn.Module classifier\n",
        "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
        "        \"\"\"\n",
        "        super(BertClassifier, self).__init__()\n",
        "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
        "        D_in, H, D_out = 768, 50, 4\n",
        "\n",
        "        # Instantiate BERT model\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        # Instantiate an one-layer feed-forward classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(D_in, H),\n",
        "            nn.ReLU(),\n",
        "            #nn.Dropout(0.5),\n",
        "            nn.Linear(H, D_out)\n",
        "        )\n",
        "\n",
        "        # Freeze the BERT model\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Feed input to BERT and the classifier to compute logits.\n",
        "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
        "                      max_length)\n",
        "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
        "                      information with shape (batch_size, max_length)\n",
        "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
        "                      num_labels)\n",
        "        \"\"\"\n",
        "        # Feed input to BERT\n",
        "        outputs = self.bert(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask)\n",
        "        \n",
        "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
        "\n",
        "        # Feed input to classifier to compute logits\n",
        "        logits = self.classifier(last_hidden_state_cls)\n",
        "\n",
        "        return logits\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwNrCgPh-yR7"
      },
      "source": [
        "##### Optimizer & Learning Rate Schedule"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6iOXiN8-8gc"
      },
      "source": [
        "\n",
        "\n",
        "- Batch size: 16 or 32\n",
        "- Learning rate (Adam): 5e-5, 3e-5 or 2e-5\n",
        "- Number of epochs: 2, 3, 4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "JX7su7Q_269U"
      },
      "outputs": [],
      "source": [
        "\n",
        "def initialize_model(epochs=4):\n",
        "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
        "    \"\"\"\n",
        "    # Instantiate Bert Classifier\n",
        "    bert_classifier = BertClassifier(freeze_bert=False)\n",
        "\n",
        "    # Tell PyTorch to run the model on GPU\n",
        "    bert_classifier.to(device)\n",
        "\n",
        "    # Create the optimizer\n",
        "    optimizer = AdamW(bert_classifier.parameters(),\n",
        "                      lr=5e-5,    # Default learning rate\n",
        "                      eps=1e-8    # Default epsilon value\n",
        "                      )\n",
        "\n",
        "    # Total number of training steps\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    # Set up the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0, # Default value\n",
        "                                                num_training_steps=total_steps)\n",
        "    return bert_classifier, optimizer, scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41DRNjv4B0Ow"
      },
      "source": [
        "##### Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYU-GQRZG0y8"
      },
      "source": [
        "In each epoch, we will train our model and evaluate its performance on the validation set.\n",
        "\n",
        "Training:\n",
        "- Unpack our data from the dataloader and load the data onto the GPU\n",
        "- Zero out gradients calculated in the previous pass\n",
        "- Perform a forward pass to compute logits and loss\n",
        "- Perform a backward pass to compute gradients (`loss.backward()`)\n",
        "- Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "- Update the model's parameters (`optimizer.step()`)\n",
        "- Update the learning rate (`scheduler.step()`)\n",
        "\n",
        "Evaluation:\n",
        "- Unpack our data and load onto the GPU\n",
        "- Forward pass\n",
        "- Compute loss and accuracy rate over the validation set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Xy4HkhyECibW"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Specify loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def set_seed(seed_value=11):\n",
        "    \"\"\"Set seed for reproducibility.\n",
        "    \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
        "    \"\"\"Train the BertClassifier model.\n",
        "    \"\"\"\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    for epoch_i in range(epochs):\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        # Measure the elapsed time of each epoch\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts +=1\n",
        "            # Load batch to GPU\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            # Zero out any previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Print the loss values and time elapsed for every 20 batches\n",
        "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                time_elapsed = time.time() - t0_batch\n",
        "\n",
        "                # Print training results\n",
        "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"-\"*70)\n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if evaluation == True:\n",
        "            # After the completion of each training epoch, measure the model's performance\n",
        "            # on our validation set.\n",
        "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
        "\n",
        "            # Print performance over the entire training data\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "            \n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "        print(\"\\n\")\n",
        "    \n",
        "    print(\"Training complete!\")\n",
        "\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5c85e0c36b88467d9e5e71eda239b73a",
            "90567f8ab6d343d090544beedd796e49",
            "0dfe627e5d4a4819b3b83fe70c3852ba",
            "ec94137dd08f43ffb23fa52bd1c00a84",
            "16c4c3fcbb204fc8bcad6eebaf6f70f8",
            "f0a52b6d544f49b08c286bbbee3bd89e",
            "98f93d30cc664b52bff4405900b80754",
            "3eb959c4cc564c52aea2375bc0b52b81",
            "c05b1abe4cda4e4bb2daa6bf15b15e67",
            "744326e80641418fbaf6c9439340cb25",
            "9b306a0595344b64b3e50b79adbff62a",
            "a350953beb3a4d8fb364277dc05f5007",
            "4ab3718f68dc4a73b0ed595d4aeb4286",
            "dbbe615ab6054c7bbe1a251f25837eab",
            "b9fffcd277544c278b40bc51b7eec138",
            "541966a2cb1147c987e59056b5d1037c",
            "bbf394594e354cbb8f50f8ff39ca5871",
            "1aec917074a1471e83832c889baa8a17",
            "da781668185b43f78f450cbabf15b8d0",
            "34477a42b38a480a90d8b416bac76a7d",
            "1ff1bd8ce90046429b432220c64977ff",
            "4f70807c560d4e639d39631fe4a97276"
          ]
        },
        "id": "wfYw7dJ0U0v6",
        "outputId": "4822185a-4af8-44ac-9b5e-b569fd46226c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c85e0c36b88467d9e5e71eda239b73a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a350953beb3a4d8fb364277dc05f5007",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1055.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   1    |   20    |   1.299037   |     -      |     -     |   6.57   \n",
            "   1    |   40    |   1.175949   |     -      |     -     |   6.13   \n",
            "   1    |   60    |   1.168837   |     -      |     -     |   6.21   \n",
            "   1    |   80    |   1.159689   |     -      |     -     |   6.25   \n",
            "   1    |   100   |   1.089584   |     -      |     -     |   6.35   \n",
            "   1    |   120   |   1.064352   |     -      |     -     |   6.34   \n",
            "   1    |   140   |   1.036401   |     -      |     -     |   6.42   \n",
            "   1    |   160   |   1.032163   |     -      |     -     |   6.49   \n",
            "   1    |   180   |   1.029988   |     -      |     -     |   6.56   \n",
            "   1    |   200   |   1.063054   |     -      |     -     |   6.66   \n",
            "   1    |   220   |   1.005741   |     -      |     -     |   6.72   \n",
            "   1    |   240   |   1.019576   |     -      |     -     |   6.78   \n",
            "   1    |   260   |   1.033788   |     -      |     -     |   6.90   \n",
            "   1    |   280   |   1.060673   |     -      |     -     |   7.03   \n",
            "   1    |   300   |   1.027001   |     -      |     -     |   7.06   \n",
            "   1    |   320   |   1.012644   |     -      |     -     |   7.19   \n",
            "   1    |   340   |   0.972523   |     -      |     -     |   7.25   \n",
            "   1    |   360   |   0.938645   |     -      |     -     |   7.19   \n",
            "   1    |   380   |   0.939508   |     -      |     -     |   7.07   \n",
            "   1    |   400   |   0.909960   |     -      |     -     |   7.00   \n",
            "   1    |   420   |   0.874422   |     -      |     -     |   6.97   \n",
            "   1    |   440   |   0.898721   |     -      |     -     |   6.95   \n",
            "   1    |   460   |   0.896686   |     -      |     -     |   6.93   \n",
            "   1    |   480   |   0.894030   |     -      |     -     |   6.93   \n",
            "   1    |   500   |   0.924938   |     -      |     -     |   6.94   \n",
            "   1    |   520   |   0.880849   |     -      |     -     |   6.97   \n",
            "   1    |   540   |   0.795935   |     -      |     -     |   6.99   \n",
            "   1    |   560   |   0.822838   |     -      |     -     |   6.99   \n",
            "   1    |   580   |   0.828073   |     -      |     -     |   7.01   \n",
            "   1    |   600   |   0.873452   |     -      |     -     |   7.03   \n",
            "   1    |   620   |   0.879780   |     -      |     -     |   7.04   \n",
            "   1    |   640   |   0.853951   |     -      |     -     |   7.02   \n",
            "   1    |   660   |   0.812338   |     -      |     -     |   7.00   \n",
            "   1    |   680   |   0.872098   |     -      |     -     |   7.00   \n",
            "   1    |   700   |   0.800781   |     -      |     -     |   6.98   \n",
            "   1    |   720   |   0.852898   |     -      |     -     |   6.98   \n",
            "   1    |   740   |   0.909182   |     -      |     -     |   6.99   \n",
            "   1    |   749   |   0.823429   |     -      |     -     |   3.15   \n",
            "----------------------------------------------------------------------\n",
            "   1    |    -    |   0.963882   |  0.806368  |   69.15   |  286.29  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.688801   |     -      |     -     |   7.37   \n",
            "   2    |   40    |   0.686805   |     -      |     -     |   7.01   \n",
            "   2    |   60    |   0.737014   |     -      |     -     |   7.01   \n",
            "   2    |   80    |   0.729860   |     -      |     -     |   7.01   \n",
            "   2    |   100   |   0.667067   |     -      |     -     |   7.00   \n",
            "   2    |   120   |   0.728252   |     -      |     -     |   6.99   \n",
            "   2    |   140   |   0.689123   |     -      |     -     |   6.99   \n",
            "   2    |   160   |   0.662877   |     -      |     -     |   6.99   \n",
            "   2    |   180   |   0.688780   |     -      |     -     |   6.98   \n",
            "   2    |   200   |   0.659903   |     -      |     -     |   6.98   \n",
            "   2    |   220   |   0.671174   |     -      |     -     |   7.00   \n",
            "   2    |   240   |   0.663873   |     -      |     -     |   7.01   \n",
            "   2    |   260   |   0.669150   |     -      |     -     |   7.02   \n",
            "   2    |   280   |   0.670833   |     -      |     -     |   7.02   \n",
            "   2    |   300   |   0.679480   |     -      |     -     |   7.03   \n",
            "   2    |   320   |   0.678290   |     -      |     -     |   7.01   \n",
            "   2    |   340   |   0.707053   |     -      |     -     |   7.00   \n",
            "   2    |   360   |   0.751544   |     -      |     -     |   7.01   \n",
            "   2    |   380   |   0.703173   |     -      |     -     |   7.00   \n",
            "   2    |   400   |   0.709104   |     -      |     -     |   6.97   \n",
            "   2    |   420   |   0.706775   |     -      |     -     |   6.99   \n",
            "   2    |   440   |   0.622967   |     -      |     -     |   6.99   \n",
            "   2    |   460   |   0.656037   |     -      |     -     |   7.00   \n",
            "   2    |   480   |   0.721631   |     -      |     -     |   7.01   \n",
            "   2    |   500   |   0.716742   |     -      |     -     |   7.01   \n",
            "   2    |   520   |   0.707739   |     -      |     -     |   7.03   \n",
            "   2    |   540   |   0.676057   |     -      |     -     |   7.03   \n",
            "   2    |   560   |   0.707542   |     -      |     -     |   7.02   \n",
            "   2    |   580   |   0.720500   |     -      |     -     |   7.01   \n",
            "   2    |   600   |   0.645728   |     -      |     -     |   7.01   \n",
            "   2    |   620   |   0.685940   |     -      |     -     |   7.00   \n",
            "   2    |   640   |   0.770161   |     -      |     -     |   7.01   \n",
            "   2    |   660   |   0.729735   |     -      |     -     |   6.98   \n",
            "   2    |   680   |   0.669906   |     -      |     -     |   6.97   \n",
            "   2    |   700   |   0.681871   |     -      |     -     |   6.98   \n",
            "   2    |   720   |   0.677351   |     -      |     -     |   6.99   \n",
            "   2    |   740   |   0.694270   |     -      |     -     |   7.01   \n",
            "   2    |   749   |   0.643655   |     -      |     -     |   3.15   \n",
            "----------------------------------------------------------------------\n",
            "   2    |    -    |   0.692192   |  0.806368  |   69.15   |  292.75  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "set_seed(11)    # Set seed for reproducibility\n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=1)\n",
        "train(bert_classifier, train_dataloader, val_dataloader, epochs=2, evaluation=True)\n",
        "filename = 'model.bin'\n",
        "model_dir = 'models/'#@param {type:\"string\"}\n",
        "torch.save(bert_classifier.state_dict(), model_dir+filename )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5ostg9kPlra"
      },
      "source": [
        "#### Evaluation on Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Em10Wz3Wsj8q",
        "outputId": "bb080228-988c-47c9-d62a-63c3afd5d42c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_path = \"models/model.bin\" #@param {type:\"string\"}\n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
        "bert_classifier.load_state_dict(torch.load(model_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "V5_w4erqGzpe"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def bert_predict(model, test_dataloader):\n",
        "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
        "    on the test set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    all_logits = []\n",
        "\n",
        "    # For each batch in our test set...\n",
        "    for batch in test_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "        all_logits.append(logits)\n",
        "    \n",
        "    # Concatenate logits from each batch\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "\n",
        "    # Apply softmax to calculate probabilities\n",
        "    probs = F.softmax(all_logits, dim=1)\n",
        "    predicted_class = torch.argmax(probs, dim=1)\n",
        "\n",
        "    return predicted_class\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao9VfL-DgZuh",
        "outputId": "177ed0fe-f9c6-4ad5-e9eb-d3ee0b62fdab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Irrelevant       0.19      0.14      0.16      1377\n",
            "    Negative       0.31      0.33      0.32      2497\n",
            "     Neutral       0.24      0.21      0.22      1956\n",
            "    Positive       0.27      0.33      0.30      2170\n",
            "\n",
            "    accuracy                           0.27      8000\n",
            "   macro avg       0.25      0.25      0.25      8000\n",
            "weighted avg       0.26      0.27      0.26      8000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred=bert_predict(bert_classifier,test_dataloader).cpu().numpy()\n",
        "print(classification_report(y_test, y_pred,target_names=list(le_name_mapping.keys())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "eaM8dKlxUx1w"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LwoYTqUVBN9"
      },
      "source": [
        "#### Inference Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "JOzKVgy2WXJ8"
      },
      "outputs": [],
      "source": [
        "  \n",
        "def bert_predict_text(model, text):\n",
        "    model.eval()\n",
        "    config={\n",
        "      \"CLASS_NAMES\": [\n",
        "        'Irrelevant', \n",
        "        'Negative', \n",
        "        'Neutral', \n",
        "        'Positive'\n",
        "      ]\n",
        "    }\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "    encoded_text = tokenizer.encode_plus(\n",
        "            text=text_preprocessing(text),  # Preprocess sentence\n",
        "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
        "            max_length=MAX_LEN,                  # Max length to truncate/pad\n",
        "            pad_to_max_length=True,         # Pad sentence to max length\n",
        "            return_tensors='pt',           # Return PyTorch tensor\n",
        "            return_attention_mask=True      # Return attention mask\n",
        "            )\n",
        "    input_ids = encoded_text[\"input_ids\"].to(device)\n",
        "    attention_mask = encoded_text[\"attention_mask\"].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        probabilities = F.softmax(model(input_ids, attention_mask), dim=1)\n",
        "    confidence, predicted_class = torch.max(probabilities, dim=1)\n",
        "    predicted_class = predicted_class.cpu().item()\n",
        "    probabilities = probabilities.flatten().cpu().numpy().tolist()\n",
        "    return (\n",
        "            config[\"CLASS_NAMES\"][predicted_class],\n",
        "            confidence.cpu().numpy(),\n",
        "            dict(zip(config[\"CLASS_NAMES\"], probabilities)),\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAxO34OxWZzb",
        "outputId": "d3e54009-7ddf-4752-869d-4dc9dfdbfe2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_path = \"models/model.bin\" #@param {type:\"string\"}\n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
        "bert_classifier.load_state_dict(torch.load(model_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtPWKsmFxUiU",
        "outputId": "58530c7f-9218-4924-b0bf-75e91ab00813"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('Positive',\n",
              " array([0.7687591], dtype=float32),\n",
              " {'Irrelevant': 0.04763031378388405,\n",
              "  'Negative': 0.0968225747346878,\n",
              "  'Neutral': 0.0867881253361702,\n",
              "  'Positive': 0.7687590718269348})"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = bert_classifier\n",
        "text = \"just played gta i think i should play other games\"#@param {type:\"string\"}\n",
        "bert_predict_text(model,text)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "31OW0dhozvli",
        "u07WRKnxsX96",
        "vU754-QPAwBt",
        "mN5Tm9SL_EO9",
        "v0mtCC3_BEZo",
        "s1SHK30JC1Rw",
        "D4sXctSh4sq0",
        "aZU8t5VNfvhY",
        "SSRAga-yj17q",
        "4wCt1I70GXr9",
        "LwNrCgPh-yR7",
        "41DRNjv4B0Ow",
        "D5ostg9kPlra"
      ],
      "name": "Sentiment-Analysis.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "26413a3d56e89f1c24e25ea29c8c417c2531fc3832505d7d7a4302a86b143ab2"
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('sentiment-analysis')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0dfe627e5d4a4819b3b83fe70c3852ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3eb959c4cc564c52aea2375bc0b52b81",
            "max": 433,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c05b1abe4cda4e4bb2daa6bf15b15e67",
            "value": 433
          }
        },
        "12bb98f0094f46728cbe28aee16ddd8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6efff40418ae420f8e6ea844f578b545",
            "placeholder": "​",
            "style": "IPY_MODEL_ad9648c5f7f14ba9a1a0b88e89e71ac1",
            "value": " 232k/232k [00:00&lt;00:00, 843kB/s]"
          }
        },
        "16c4c3fcbb204fc8bcad6eebaf6f70f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "175ffd8bc76f4c97838e4d55810442de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1aec917074a1471e83832c889baa8a17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1efbc257acf34799a229416bf3949ac6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48760076390940659b2410f899d25c29",
              "IPY_MODEL_b4e1abe735774de99a74990c1c35fd5b",
              "IPY_MODEL_12bb98f0094f46728cbe28aee16ddd8b"
            ],
            "layout": "IPY_MODEL_f612e71b983f4ebb8d6a2a05815cb034"
          }
        },
        "1ff1bd8ce90046429b432220c64977ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34477a42b38a480a90d8b416bac76a7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3eb959c4cc564c52aea2375bc0b52b81": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48760076390940659b2410f899d25c29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5fe82b81731427bbb5811879165a3e2",
            "placeholder": "​",
            "style": "IPY_MODEL_175ffd8bc76f4c97838e4d55810442de",
            "value": "Downloading: 100%"
          }
        },
        "4ab3718f68dc4a73b0ed595d4aeb4286": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbf394594e354cbb8f50f8ff39ca5871",
            "placeholder": "​",
            "style": "IPY_MODEL_1aec917074a1471e83832c889baa8a17",
            "value": "Downloading: 100%"
          }
        },
        "4f70807c560d4e639d39631fe4a97276": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "541966a2cb1147c987e59056b5d1037c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c85e0c36b88467d9e5e71eda239b73a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90567f8ab6d343d090544beedd796e49",
              "IPY_MODEL_0dfe627e5d4a4819b3b83fe70c3852ba",
              "IPY_MODEL_ec94137dd08f43ffb23fa52bd1c00a84"
            ],
            "layout": "IPY_MODEL_16c4c3fcbb204fc8bcad6eebaf6f70f8"
          }
        },
        "6efff40418ae420f8e6ea844f578b545": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "744326e80641418fbaf6c9439340cb25": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78e349dbec594a5292b7f1e696324e9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90567f8ab6d343d090544beedd796e49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0a52b6d544f49b08c286bbbee3bd89e",
            "placeholder": "​",
            "style": "IPY_MODEL_98f93d30cc664b52bff4405900b80754",
            "value": "Downloading: 100%"
          }
        },
        "98f93d30cc664b52bff4405900b80754": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b306a0595344b64b3e50b79adbff62a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a350953beb3a4d8fb364277dc05f5007": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ab3718f68dc4a73b0ed595d4aeb4286",
              "IPY_MODEL_dbbe615ab6054c7bbe1a251f25837eab",
              "IPY_MODEL_b9fffcd277544c278b40bc51b7eec138"
            ],
            "layout": "IPY_MODEL_541966a2cb1147c987e59056b5d1037c"
          }
        },
        "ad9648c5f7f14ba9a1a0b88e89e71ac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0b2959cac6c497c96e3af39ba30a01f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4e1abe735774de99a74990c1c35fd5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0b2959cac6c497c96e3af39ba30a01f",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_78e349dbec594a5292b7f1e696324e9b",
            "value": 231508
          }
        },
        "b9fffcd277544c278b40bc51b7eec138": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ff1bd8ce90046429b432220c64977ff",
            "placeholder": "​",
            "style": "IPY_MODEL_4f70807c560d4e639d39631fe4a97276",
            "value": " 440M/440M [00:07&lt;00:00, 55.7MB/s]"
          }
        },
        "bbf394594e354cbb8f50f8ff39ca5871": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c05b1abe4cda4e4bb2daa6bf15b15e67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d5fe82b81731427bbb5811879165a3e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da781668185b43f78f450cbabf15b8d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbbe615ab6054c7bbe1a251f25837eab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da781668185b43f78f450cbabf15b8d0",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34477a42b38a480a90d8b416bac76a7d",
            "value": 440473133
          }
        },
        "ec94137dd08f43ffb23fa52bd1c00a84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_744326e80641418fbaf6c9439340cb25",
            "placeholder": "​",
            "style": "IPY_MODEL_9b306a0595344b64b3e50b79adbff62a",
            "value": " 433/433 [00:00&lt;00:00, 12.0kB/s]"
          }
        },
        "f0a52b6d544f49b08c286bbbee3bd89e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f612e71b983f4ebb8d6a2a05815cb034": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
